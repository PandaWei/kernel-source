From 2165e85b0afe79d153be8adf00652da147ddd6f1 Mon Sep 17 00:00:00 2001
From: Vlastimil Babka <vbabka@suse.cz>
Date: Thu, 2 Aug 2018 10:56:41 +0200
Subject: [PATCH] x64/entry: move ENABLE_IBRS after switching from trampoline
 stack
Patch-mainline: never, different implementation
References: bsc#1098658

In the current error_entry, ENABLE_IBRS is performed under error_swapgs label
before switching from trampoline stack to kernel thread stack under error_sti.
It also switches to kernel thread stack temporarily and unconditionally, while
the proper switch checks first that we are indeed on the trampoline stack.

This might be a problem when we jump to error_swapgs from error_kernelspace
which means the kernel faulted in gs_change. AFAIU that's on the kernel stack,
so by switching to its beginning means we would overwrite it.

There are also jumps to error_sti from error_bad_iret, which means this path
would miss ENABLE_IBRS. It's also a bit wasteful to switch the stack twice.

To resolve all above, move ENABLE_IBRS after the (conditional) stack switch
under error_sti.

Signed-off-by: Vlastimil Babka <vbabka@suse.cz>
---
 arch/x86/kernel/entry_64.S | 6 ++----
 1 file changed, 2 insertions(+), 4 deletions(-)

diff --git a/arch/x86/kernel/entry_64.S b/arch/x86/kernel/entry_64.S
index 8f2c9d5d4927..418ec6a0b079 100644
--- a/arch/x86/kernel/entry_64.S
+++ b/arch/x86/kernel/entry_64.S
@@ -1627,10 +1627,6 @@ ENTRY(error_entry)
 error_swapgs:
 	SWAPGS
 	SWITCH_KERNEL_CR3
-	movq %rsp, %rsi
-	movq PER_CPU_VAR(kernel_stack), %rsp
-	ENABLE_IBRS
-	movq %rsi, %rsp
 error_sti:
 	movq PER_CPU_VAR(init_tss + TSS_sp0), %rcx
 	cmpq %rcx, %rsp
@@ -1646,6 +1642,8 @@ ENTRY(error_entry)
 	movq %rsp, %rsi
 	rep movsb
 	movq %rax, %rsp
+
+	ENABLE_IBRS
 1:
 	TRACE_IRQS_OFF
 	ret
-- 
2.18.0

