From: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
Date: Wed, 9 May 2018 21:41:38 +0200
Subject: xen/x86/bugs: Rename _RDS to _SSBD
Patch-mainline: Never, SUSE-Xen specific
References: bsc#1087082 CVE-2018-3639

Intel collateral will reference the SSB mitigation bit in IA32_SPEC_CTL[2]
as SSBD (Speculative Store Bypass Disable).

Hence changing it.

It is unclear yet what the MSR_IA32_ARCH_CAPABILITIES (0x10a) Bit(4) name
is going to be. Following the rename it would be SSBD_NO but that rolls out
to Speculative Store Bypass Disable No.

Also fixed the missing space in X86_FEATURE_AMD_SSBD.

[ tglx: Fixup x86_amd_rds_enable() and rds_tif_to_amd_ls_cfg() as well ]

Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
Acked-by: Borislav Petkov <bp@suse.de>
Automatically created from "patches.arch/26-x86-bugs-rename-rds-to-ssbd.patch" by xen-port-patches.py

--- a/arch/x86/kernel/cpu/bugs.c
+++ b/arch/x86/kernel/cpu/bugs.c
@@ -824,7 +824,7 @@ static void x86_amd_ssbd_disable(void)
 	u64 msrval = x86_amd_ls_cfg_base | x86_amd_ls_cfg_ssbd_mask;
 
 #ifdef CONFIG_XEN
-	if (x86_amd_ls_cfg_base & x86_amd_ls_cfg_rds_mask)
+	if (x86_amd_ls_cfg_base & x86_amd_ls_cfg_ssbd_mask)
 		return;
 #endif
 
--- a/arch/x86/kernel/process-xen.c
+++ b/arch/x86/kernel/process-xen.c
@@ -198,8 +198,8 @@ static __always_inline void __speculativ
 {
 	u64 msr;
 
-	if (static_cpu_has(X86_FEATURE_AMD_RDS)) {
-		msr = x86_amd_ls_cfg_base | rds_tif_to_amd_ls_cfg(rds);
+	if (static_cpu_has(X86_FEATURE_AMD_SSBD)) {
+		msr = x86_amd_ls_cfg_base | ssbd_tif_to_amd_ls_cfg(rds);
 #ifdef CONFIG_XEN
 		/*
 		 * At the moment Xen does not virtualize LS_CFG, and it
@@ -210,11 +210,11 @@ static __always_inline void __speculativ
 		 * zero, but that would be more involved. If any guest is to
 		 * rely on the feature, Xen better had it enabled globally.)
 		 */
-		if (!(x86_amd_ls_cfg_base & x86_amd_ls_cfg_rds_mask))
+		if (!(x86_amd_ls_cfg_base & x86_amd_ls_cfg_ssbd_mask))
 #endif
 		wrmsrl(MSR_AMD64_LS_CFG, msr);
 	} else {
-		msr = x86_spec_ctrl_base | rds_tif_to_spec_ctrl(rds);
+		msr = x86_spec_ctrl_base | ssbd_tif_to_spec_ctrl(rds);
 		wrmsrl(MSR_IA32_SPEC_CTRL, msr);
 	}
 }
@@ -251,9 +251,9 @@ void __switch_to_xtra(struct task_struct
 			hard_enable_TSC();
 	}
 
-	if (test_tsk_thread_flag(prev_p, TIF_RDS) ^
-	    test_tsk_thread_flag(next_p, TIF_RDS))
-		__speculative_store_bypass_update(test_tsk_thread_flag(next_p, TIF_RDS));
+	if (test_tsk_thread_flag(prev_p, TIF_SSBD) ^
+	    test_tsk_thread_flag(next_p, TIF_SSBD))
+		__speculative_store_bypass_update(test_tsk_thread_flag(next_p, TIF_SSBD));
 
 	propagate_user_return_notify(prev_p, next_p);
 }
--- a/arch/x86/include/asm/thread_info.h
+++ b/arch/x86/include/asm/thread_info.h
@@ -155,7 +155,7 @@ struct thread_info {
 	(_TIF_IO_BITMAP|_TIF_NOTSC|_TIF_BLOCKSTEP|_TIF_SSBD)
 
 #else
-#define _TIF_WORK_CTXSW (_TIF_NOTSC /*todo | _TIF_BLOCKSTEP */ | _TIF_RDS)
+#define _TIF_WORK_CTXSW (_TIF_NOTSC /*todo | _TIF_BLOCKSTEP */ | _TIF_SSBD)
 #endif
 #define _TIF_WORK_CTXSW_PREV (_TIF_WORK_CTXSW|_TIF_USER_RETURN_NOTIFY)
 #define _TIF_WORK_CTXSW_NEXT (_TIF_WORK_CTXSW|_TIF_DEBUG)
