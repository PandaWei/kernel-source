From: Dave Hansen <dave.hansen@linux.intel.com>
Date: Wed, 9 May 2018 20:46:12 +0200
Subject: x86, bugs: centralize SPEC_CTRL MSR mask generation
Patch-mainline: Not yet, work in progress
References: bsc#1087082 CVE-2018-3639

The KVM code manipualtes the SPEC_CTRL MSR when it enters and exits
the guest.  It overwrites the "kernel" value when it enters the guest
and restores the "kernel" value after leaving the guest.

Both code paths take into account the "base" (x86_spec_ctrl_base)
value and the per-task TIF_RDS flag (on Intel).  They then see if the
new state differs from the existing state and avoid the MSR write if
no change is made.

But, these two paths could be a bit more unified.  Introduce a new
function: x86_calculate_kernel_spec_ctrl() which will figure out the
"kernel" value to contrast it with the "guest" value.  We also
rename the arguments to the set/restore functions to make it clear
that while the arguments are both "guest" state, they really mean
different things to the two functions.

This will make the next step easier when we have more state to
consult in doing the x86_calculate_kernel_spec_ctrl() calculatione

Signed-off-by: Dave Hansen <dave.hansen@linux.intel.com>
Cc: Andi Kleen <ak@linux.intel.com>
Cc: Tim Chen <tim.c.chen@linux.intel.com>
Reviewed-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
Signed-off-by: Joerg Roedel <jroedel@suse.de>
---
 arch/x86/kernel/cpu/bugs.c | 49 ++++++++++++++++++++++++++++++----------------
 1 file changed, 32 insertions(+), 17 deletions(-)

diff --git a/arch/x86/kernel/cpu/bugs.c b/arch/x86/kernel/cpu/bugs.c
index c3d73781..c0b804a5 100644
--- a/arch/x86/kernel/cpu/bugs.c
+++ b/arch/x86/kernel/cpu/bugs.c
@@ -785,33 +785,48 @@ u64 x86_spec_ctrl_get_default(void)
 }
 EXPORT_SYMBOL_GPL(x86_spec_ctrl_get_default);
 
-void x86_spec_ctrl_set_guest(u64 guest_spec_ctrl)
+static inline u64 intel_rds_mask(void)
 {
-	u64 host = x86_spec_ctrl_base;
+	if (boot_cpu_data.x86_vendor != X86_VENDOR_INTEL)
+		return 0;
 
+	return rds_tif_to_spec_ctrl(current_thread_info()->flags);
+}
+
+/*
+ * Calculate the SPEC_CTRL MSR value that the kernel
+ * should be using under normal operation.
+ */
+static u64 x86_calculate_kernel_spec_ctrl(void)
+{
+	u64 spec_ctrl;
 	if (!boot_cpu_has(X86_FEATURE_IBRS))
-		return;
+		return 0;
 
-	if (boot_cpu_data.x86_vendor == X86_VENDOR_INTEL)
-		host |= rds_tif_to_spec_ctrl(current_thread_info()->flags);
+	spec_ctrl = x86_spec_ctrl_base;
+	spec_ctrl |= intel_rds_mask();
 
-	if (host != guest_spec_ctrl)
-		wrmsrl(MSR_IA32_SPEC_CTRL, guest_spec_ctrl);
+	return spec_ctrl;
 }
-EXPORT_SYMBOL_GPL(x86_spec_ctrl_set_guest);
 
-void x86_spec_ctrl_restore_host(u64 guest_spec_ctrl)
+/* We are entering a guest and need to set its MSR value. */
+void x86_spec_ctrl_set_guest(u64 new_spec_ctrl)
 {
-	u64 host = x86_spec_ctrl_base;
-
-	if (!boot_cpu_has(X86_FEATURE_IBRS))
-		return;
+	if (x86_calculate_kernel_spec_ctrl() != new_spec_ctrl)
+		wrmsrl(MSR_IA32_SPEC_CTRL, new_spec_ctrl);
+}
+EXPORT_SYMBOL_GPL(x86_spec_ctrl_set_guest);
 
-	if (boot_cpu_data.x86_vendor == X86_VENDOR_INTEL)
-		host |= rds_tif_to_spec_ctrl(current_thread_info()->flags);
+/*
+ * We are leaving a guest and need to restore the kernel's MSR
+ * value that it uses for normal operation.
+ */
+void x86_spec_ctrl_restore_host(u64 current_spec_ctrl)
+{
+	u64 new_spec_ctrl = x86_calculate_kernel_spec_ctrl();
 
-	if (host != guest_spec_ctrl)
-		wrmsrl(MSR_IA32_SPEC_CTRL, host);
+	if (new_spec_ctrl != current_spec_ctrl)
+		wrmsrl(MSR_IA32_SPEC_CTRL, new_spec_ctrl);
 }
 EXPORT_SYMBOL_GPL(x86_spec_ctrl_restore_host);
 
-- 
2.12.3

