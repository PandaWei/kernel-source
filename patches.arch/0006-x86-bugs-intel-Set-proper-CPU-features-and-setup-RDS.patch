From c02e050902c50f74286a1c5ebff18bba6bb0fca0 Mon Sep 17 00:00:00 2001
From: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
Date: Wed, 25 Apr 2018 22:04:22 -0400
Subject: x86/bugs/intel: Set proper CPU features and setup RDS
Patch-mainline: not yet, queued in subsystem tree
References: bsc#1087082 CVE-2018-3639

Intel CPUs expose methods to:

 - Detect whether RDS capability is available via CPUID.7.0.EDX[31],

 - The SPEC_CTRL MSR(0x48), bit 2 set to enable RDS.

 - MSR_IA32_ARCH_CAPABILITIES, Bit(4) no need to enable RRS.

With that in mind if spec_store_bypass_disable=[auto,on] is selected set at
boot-time the SPEC_CTRL MSR to enable RDS if the platform requires it.

Note that this does not fix the KVM case where the SPEC_CTRL is exposed to
guests which can muck with it, see patch titled :
 KVM/SVM/VMX/x86/spectre_v2: Support the combination of guest and host IBRS.

And for the firmware (IBRS to be set), see patch titled:
 x86/spectre_v2: Read SPEC_CTRL MSR during boot and re-use reserved bits

[ tglx: Distangled it from the intel implementation and kept the call order ]

Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
Reviewed-by: Borislav Petkov <bp@suse.de>
Reviewed-by: Ingo Molnar <mingo@kernel.org>
Acked-by: Joerg Roedel <jroedel@suse.de>
---
 arch/x86/include/asm/cpu.h   |  2 ++
 arch/x86/kernel/cpu/bugs.c   | 33 +++++++++++++++++++++++++++++++--
 arch/x86/kernel/cpu/common.c |  2 ++
 3 files changed, 35 insertions(+), 2 deletions(-)

--- a/arch/x86/include/asm/cpu.h
+++ b/arch/x86/include/asm/cpu.h
@@ -34,4 +34,6 @@
 
 int mwait_usable(const struct cpuinfo_x86 *);
 
+extern void x86_spec_ctrl_setup_ap(void);
+
 #endif /* _ASM_X86_CPU_H */
--- a/arch/x86/kernel/cpu/bugs.c
+++ b/arch/x86/kernel/cpu/bugs.c
@@ -519,8 +519,28 @@
 			break;
 	}
 
-	if (mode != SPEC_STORE_BYPASS_NONE)
+	/*
+	 * We have three CPU feature flags that are in play here:
+	 *  - X86_BUG_SPEC_STORE_BYPASS - CPU is susceptible.
+	 *  - X86_FEATURE_RDS - CPU is able to turn off speculative store bypass
+	 *  - X86_FEATURE_SPEC_STORE_BYPASS_DISABLE - engage the mitigation
+         */
+	if (mode != SPEC_STORE_BYPASS_NONE) {
 		setup_force_cpu_cap(X86_FEATURE_SPEC_STORE_BYPASS_DISABLE);
+		/*
+		 * Intel uses the SPEC CTRL MSR Bit(2) for this, while AMD uses
+		 * a completely different MSR and bit dependent on family.
+		 */
+		switch (boot_cpu_data.x86_vendor) {
+			case X86_VENDOR_INTEL:
+				x86_spec_ctrl_base |= SPEC_CTRL_RDS;
+				x86_spec_ctrl_set(SPEC_CTRL_RDS);
+				break;
+			case X86_VENDOR_AMD:
+				break;
+		}
+	}
+
 	return mode;
 }
 
@@ -534,6 +554,12 @@
 
 #undef pr_fmt
 
+void x86_spec_ctrl_setup_ap(void)
+{
+	if (boot_cpu_has(X86_FEATURE_IBRS))
+		x86_spec_ctrl_set(x86_spec_ctrl_base & (SPEC_CTRL_IBRS | SPEC_CTRL_RDS));
+}
+
 #ifdef CONFIG_SYSFS
 ssize_t cpu_show_meltdown(struct device *dev,
 			  struct device_attribute *attr, char *buf)
@@ -578,7 +604,10 @@
 
 void x86_spec_ctrl_set(u64 val)
 {
-	wrmsrl(MSR_IA32_SPEC_CTRL, x86_spec_ctrl_base | val);
+	if (val & ~(SPEC_CTRL_IBRS | SPEC_CTRL_RDS))
+		WARN_ONCE(1, "SPEC_CTRL MSR value 0x%16llx is unknown.\n", val);
+	else
+		wrmsrl(MSR_IA32_SPEC_CTRL, x86_spec_ctrl_base | val);
 }
 EXPORT_SYMBOL_GPL(x86_spec_ctrl_set);
 
--- a/arch/x86/kernel/cpu/common.c
+++ b/arch/x86/kernel/cpu/common.c
@@ -1028,6 +1028,8 @@
 	enable_sep_cpu();
 #endif
 	mtrr_ap_init();
+
+	x86_spec_ctrl_setup_ap();
 }
 
 struct msr_range {
